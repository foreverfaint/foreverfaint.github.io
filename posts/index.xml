<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Dev66</title><link>https://foreverfaint.github.io/posts/</link><description>Recent content in Posts on Dev66</description><generator>Hugo -- gohugo.io</generator><language>zh-Hant</language><copyright>&amp;copy; Copyright notice</copyright><lastBuildDate>Thu, 24 Feb 2022 17:12:22 +0800</lastBuildDate><atom:link href="https://foreverfaint.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>TensorRT容器镜像</title><link>https://foreverfaint.github.io/posts/build-tensorrt-docker-image/</link><pubDate>Thu, 24 Feb 2022 17:12:22 +0800</pubDate><guid>https://foreverfaint.github.io/posts/build-tensorrt-docker-image/</guid><description>&lt;p>首先，NVIDIA NGC为每个TensorRT的版本提供了&lt;a href="https://docs.nvidia.com/deeplearning/tensorrt/container-release-notes/rel_22-01.html">docker镜像&lt;/a>。具体的镜像使用方法参见&lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorrt">NGC TensorRT页面&lt;/a> 。简单说，开发者基于官方镜像build自己的镜像。&lt;/p></description></item><item><title>360环评</title><link>https://foreverfaint.github.io/posts/360-feedback/</link><pubDate>Sun, 17 Jan 2021 15:04:00 +0800</pubDate><guid>https://foreverfaint.github.io/posts/360-feedback/</guid><description>&lt;p>这是我司第二年做360环评。第一次环评时，发生了被反馈者拿着反馈结果找提供反馈的同事吵架的事请。这事儿隔了一年我才知道，感慨颇深：&lt;/p></description></item><item><title>如何算一篇好的阐述并解决问题的博文？</title><link>https://foreverfaint.github.io/posts/first-try-on-flutter/</link><pubDate>Mon, 10 Feb 2020 00:02:00 +0800</pubDate><guid>https://foreverfaint.github.io/posts/first-try-on-flutter/</guid><description>&lt;p>最近在学习Flutter开发Android应用。新手搭环境难免遇到各种坑。一般都是边搜索边尝试，最终解决问题。因此“搜索”到别人的解法至关重要。我发现网上有大量的解法，但很多时候，要么“解法”缺斤短两，关键步骤缺失；要么知其然不知所以然，瞎猫碰死耗子解决问题，让读者无法借鉴。到底如何才算一篇合格的issue resolution博文，怎样才能帮到他人？&lt;/p></description></item><item><title>nohup</title><link>https://foreverfaint.github.io/posts/nohup/</link><pubDate>Sun, 19 Jan 2020 00:00:00 +0800</pubDate><guid>https://foreverfaint.github.io/posts/nohup/</guid><description>&lt;p>nohup是一个POSIX命令。人如其名“NO”+“HUP（hangup）”，“HUP”是挂起信号，“NOHUP”就是忽略挂起信号。&lt;/p></description></item><item><title>在Scrapy中使用cookie</title><link>https://foreverfaint.github.io/posts/scrapy-cookie/</link><pubDate>Fri, 11 Dec 2015 15:27:56 +0800</pubDate><guid>https://foreverfaint.github.io/posts/scrapy-cookie/</guid><description>&lt;p>Python有一个很出色的爬虫包&lt;a href="http://scrapy.org/">scrapy&lt;/a>，架构清晰，设计精巧，能想到的爬虫工具需要的定制化点都有对应的扩展机制。 大部分网站都使用cookie来记录访问用户的识别信息。每个请求都会把用户识别信息带回到服务器，帮助后台程序识别独立用户，这样可以进行鉴权，反爬，限流等很多的操作。所以对于爬虫来说，如何模拟和使用cookie“欺骗”服务器，是十分重要的一步。本文就介绍如何在scrapy中使用cookie技术。&lt;/p></description></item><item><title>Streaming Pipeline in Python - 1</title><link>https://foreverfaint.github.io/posts/streaming-pipeline-in-python-1/</link><pubDate>Sun, 01 Nov 2015 00:00:00 +0800</pubDate><guid>https://foreverfaint.github.io/posts/streaming-pipeline-in-python-1/</guid><description>&lt;p>最近用python 2.7做数据处理。数据说大不大，说小不小，千万级别。显然用Hadoop是大材小用。可由于每笔数据都是一个很大的json对象，处理起来很耗内存。单机加到8GB，依旧会出现OOM。不过还好此类问题有成熟的解决方案“流水线式的数据处理”：每次从文件读一笔记录数据，处理一笔数据，把处理结果持久化，相应的对象实例（内存）被回收。方案成熟易实现。先把代码列在下面，然后再解释其中遇到的坑。&lt;/p></description></item></channel></rss>